---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: garage-init
  namespace: garage
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: garage-init
  namespace: garage
rules:
  - apiGroups: [""]
    resources: ["pods", "pods/exec"]
    verbs: ["get", "list", "watch", "create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: garage-init
  namespace: garage
subjects:
  - kind: ServiceAccount
    name: garage-init
    namespace: garage
roleRef:
  kind: Role
  name: garage-init
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: garage-init-namespaces
rules:
  - apiGroups: [""]
    resources: ["namespaces"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: garage-init-namespaces
subjects:
  - kind: ServiceAccount
    name: garage-init
    namespace: garage
roleRef:
  kind: ClusterRole
  name: garage-init-namespaces
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: batch/v1
kind: Job
metadata:
  name: garage-init
  namespace: garage
spec:
  template:
    spec:
      serviceAccountName: garage-init
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: garage-init
          image: docker.io/alpine/kubectl:1.35.0
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          resources:
            requests:
              cpu: 10m
              memory: 32Mi
            limits:
              cpu: 100m
              memory: 128Mi
          command:
            - /bin/sh
            - -c
            - |
              set -e

              GARAGE_POD="garage-0"

              # Wait for Garage pod to be ready
              echo "Waiting for Garage pod..."
              kubectl wait --for=condition=ready pod/$GARAGE_POD -n garage --timeout=300s

              # Check if layout is already configured
              echo "Checking layout..."
              if kubectl exec -n garage $GARAGE_POD -c garage -- ./garage layout show 2>/dev/null | grep -q "Current cluster layout version: [1-9]"; then
                echo "Layout is already configured"
              else
                echo "Layout not configured, setting up automatically..."

                # Get all node IDs from garage status
                NODE_IDS=$(kubectl exec -n garage $GARAGE_POD -c garage -- ./garage status 2>/dev/null | grep "NO ROLE ASSIGNED" | awk '{print $1}')

                if [ -z "$NODE_IDS" ]; then
                  echo "ERROR: No nodes found in garage status"
                  exit 1
                fi

                # Assign each node to zone dc1 with 50G capacity
                for NODE_ID in $NODE_IDS; do
                  echo "Assigning node $NODE_ID..."
                  kubectl exec -n garage $GARAGE_POD -c garage -- ./garage layout assign "$NODE_ID" -z dc1 -c 50G
                done

                # Apply the layout
                echo "Applying layout..."
                kubectl exec -n garage $GARAGE_POD -c garage -- ./garage layout apply --version 1

                echo "Layout configured successfully"
              fi

              # Create bucket if not exists
              if ! kubectl exec -n garage $GARAGE_POD -c garage -- ./garage bucket list 2>/dev/null | grep -q "cnpg-backups"; then
                echo "Creating bucket cnpg-backups..."
                kubectl exec -n garage $GARAGE_POD -c garage -- ./garage bucket create cnpg-backups
              else
                echo "Bucket cnpg-backups already exists"
              fi

              # Create key if not exists
              if ! kubectl exec -n garage $GARAGE_POD -c garage -- ./garage key list 2>/dev/null | grep -q "cnpg-backup-key"; then
                echo "Creating key cnpg-backup-key..."
                kubectl exec -n garage $GARAGE_POD -c garage -- ./garage key create cnpg-backup-key
                kubectl exec -n garage $GARAGE_POD -c garage -- ./garage bucket allow cnpg-backups --read --write --key cnpg-backup-key
              else
                echo "Key cnpg-backup-key already exists"
              fi

              # Get key credentials (with --show-secret to get the actual secret)
              echo "=== Extracting Key Credentials ==="
              KEY_INFO=$(kubectl exec -n garage $GARAGE_POD -c garage -- ./garage key info cnpg-backup-key --show-secret)
              # Don't echo full output to avoid leaking secret in logs

              ACCESS_KEY_ID=$(echo "$KEY_INFO" | grep "Key ID:" | awk '{print $3}')
              ACCESS_SECRET_KEY=$(echo "$KEY_INFO" | grep "Secret key:" | awk '{print $3}')

              if [ -z "$ACCESS_KEY_ID" ] || [ -z "$ACCESS_SECRET_KEY" ]; then
                echo "ERROR: Failed to extract key credentials"
                exit 1
              fi

              echo "Access Key ID: $ACCESS_KEY_ID"
              echo "Secret Key: [REDACTED]"

              # Create/update secret in authentik namespace
              echo "=== Creating S3 credentials secret in authentik namespace ==="

              # Wait for authentik namespace (created by Flux before this job runs)
              echo "Waiting for authentik namespace..."
              until kubectl get namespace authentik >/dev/null 2>&1; do
                echo "Namespace authentik not ready yet, waiting..."
                sleep 5
              done

              # Create or update the secret
              kubectl create secret generic cnpg-s3-credentials \
                --namespace=authentik \
                --from-literal=ACCESS_KEY_ID="$ACCESS_KEY_ID" \
                --from-literal=ACCESS_SECRET_KEY="$ACCESS_SECRET_KEY" \
                --dry-run=client -o yaml | kubectl apply -f -

              echo "=== Secret cnpg-s3-credentials created/updated in authentik namespace ==="
              echo "Garage init completed successfully!"
